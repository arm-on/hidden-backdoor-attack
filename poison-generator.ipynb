{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from torch import cuda\n",
    "from torch.backends import mps\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_filelist(folder_path, extension):\n",
    "    return glob.glob(os.path.join(folder_path, f'*.{extension}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else ('mps' if mps.is_available() else 'cpu')\n",
    "seed = 50\n",
    "experimentID = 'arman'\n",
    "patch_size = 30\n",
    "eps = 16\n",
    "logfile = './kaggle/working/logs/report.log'\n",
    "epochs = 2\n",
    "lr = 0.01\n",
    "num_source = 1\n",
    "rand_loc = True\n",
    "num_iter = 5000\n",
    "batch_size = 100 # should be 100 for the real experiment\n",
    "num_workers = 1 # should be 8 for the real experiment\n",
    "trigger_path = 'data/triggers/trigger_14.png'\n",
    "source_filelist = get_folder_filelist('/Users/armanmalekzadeh/Documents/GitHub/hidden-trigger-backdoor-attack/data/source/n03461385', 'JPEG')\n",
    "target_filelist = get_folder_filelist('/Users/armanmalekzadeh/Documents/GitHub/hidden-trigger-backdoor-attack/data/source/n02437312', 'JPEG')[:200]\n",
    "saveDir_patched = './kaggle/working/patched_data/'\n",
    "saveDir_poison = './kaggle/working/poison_data/'\n",
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "}\n",
    "if os.path.exists(saveDir_poison):\n",
    "    shutil.rmtree(saveDir_poison)\n",
    "os.makedirs(saveDir_poison)\n",
    "if os.path.exists(saveDir_patched):\n",
    "    shutil.rmtree(saveDir_patched)\n",
    "os.makedirs(saveDir_patched)\n",
    "    \n",
    "### I have to define the number of classes when defining the alexnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_info(msg):\n",
    "    with open(logfile, 'a+') as file:\n",
    "        file.write(f'{msg} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_fn(tensor, mean, std):\n",
    "    \"\"\"Differentiable version of torchvision.functional.normalize\"\"\"\n",
    "    # here we assume the color channel is in at dim=1\n",
    "    mean = mean[None, :, None, None]\n",
    "    std = std[None, :, None, None]\n",
    "    return tensor.sub(mean).div(std)\n",
    "\n",
    "class NormalizeByChannelMeanStd(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(NormalizeByChannelMeanStd, self).__init__()\n",
    "        if not isinstance(mean, torch.Tensor):\n",
    "            mean = torch.tensor(mean)\n",
    "        if not isinstance(std, torch.Tensor):\n",
    "            std = torch.tensor(std)\n",
    "        self.register_buffer(\"mean\", mean)\n",
    "        self.register_buffer(\"std\", std)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return normalize_fn(tensor, self.mean, self.std)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'mean={}, std={}'.format(self.mean, self.std)\n",
    "    \n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        # feat = x.view(x.size(0), 256 * 6 * 6)           # conv5 features\n",
    "        x = self.avgpool(x)\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        for i in range(6):\n",
    "            x = self.classifier[i](x)\n",
    "        feat = x                                        # fc7 features\n",
    "        x = self.classifier[6](x)\n",
    "\n",
    "#        x = self.classifier(x)\n",
    "        return x, feat\n",
    "\n",
    "def alexnet(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = AlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "\tnpimg = img.numpy()\n",
    "\tplt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "\tplt.show()\n",
    "def save_image(img, fname):\n",
    "\timg = img.data.numpy()\n",
    "\timg = np.transpose(img, (1, 2, 0))\n",
    "\timg = img[: , :, ::-1]\n",
    "\tcv2.imwrite(fname, np.uint8(255 * img), [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "def adjust_learning_rate(lr, iter):\n",
    "\t\"\"\"Sets the learning rate to the initial LR decayed by 0.5 every 1000 iterations\"\"\"\n",
    "\tlr = lr * (0.5 ** (iter // 1000))\n",
    "\treturn lr\n",
    "class AverageMeter(object):\n",
    "\t\"\"\"Computes and stores the average and current value\"\"\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.reset()\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.val = 0\n",
    "\t\tself.avg = 0\n",
    "\t\tself.sum = 0\n",
    "\t\tself.count = 0\n",
    "\n",
    "\tdef update(self, val, n=1):\n",
    "\t\tself.val = val\n",
    "\t\tself.sum += val * n\n",
    "\t\tself.count += n\n",
    "\t\tself.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoisonGenerationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.file_list[idx]\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, image_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "\n",
    "\tsince = time.time()\n",
    "\t# AVERAGE METER\n",
    "\tlosses = AverageMeter()\n",
    "\n",
    "\t# TRIGGER PARAMETERS\n",
    "\ttrans_image = transforms.Compose([transforms.Resize((224, 224)),\n",
    "\t\t\t\t\t\t\t\t\t  transforms.ToTensor(),\n",
    "\t\t\t\t\t\t\t\t\t  ])\n",
    "\ttrans_trigger = transforms.Compose([transforms.Resize((patch_size, patch_size)),\n",
    "\t\t\t\t\t\t\t\t\t\ttransforms.ToTensor(),\n",
    "\t\t\t\t\t\t\t\t\t\t])\n",
    "\n",
    "\t# PERTURBATION PARAMETERS\n",
    "\teps1 = (eps/255.0)\n",
    "\tlr1 = lr\n",
    "\n",
    "\ttrigger = Image.open(trigger_path).convert('RGB')\n",
    "\ttrigger = trans_trigger(trigger).unsqueeze(0).to(device)\n",
    "\n",
    "\t# Use source wnid list\n",
    "\tif num_source==1:\n",
    "\t\tlogging.info(\"Using single source for this experiment.\")\n",
    "\telse:\n",
    "\t\tlogging.info(\"Using multiple source for this experiment.\")\n",
    "\n",
    "\n",
    "\tdataset_target = PoisonGenerationDataset(target_filelist, trans_image)\n",
    "\tdataset_source = PoisonGenerationDataset(source_filelist, trans_image)\n",
    "\n",
    "\t# SOURCE AND TARGET DATALOADERS\n",
    "\ttrain_loader_target = torch.utils.data.DataLoader(dataset_target,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t# num_workers=num_workers,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tpin_memory=True)\n",
    "\n",
    "\ttrain_loader_source = torch.utils.data.DataLoader(dataset_source,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  batch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  shuffle=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t#   num_workers=num_workers,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  pin_memory=True)\n",
    "\n",
    "\n",
    "\tlogging.info(\"Number of target images:{}\".format(len(dataset_target)))\n",
    "\tlogging.info(\"Number of source images:{}\".format(len(dataset_source)))\n",
    "\n",
    "\t# USE ITERATORS ON DATALOADERS TO HAVE DISTINCT PAIRING EACH TIME\n",
    "\titer_target = iter(train_loader_target)\n",
    "\titer_source = iter(train_loader_source)\n",
    "\n",
    "\tnum_poisoned = 0\n",
    "\tfor i in range(len(train_loader_target)):\n",
    "\n",
    "\t\t# LOAD ONE BATCH OF SOURCE AND ONE BATCH OF TARGET\n",
    "\t\t(input1, path1) = next(iter_source)\n",
    "\t\t(input2, path2) = next(iter_target)\n",
    "\n",
    "\t\timg_ctr = 0\n",
    "\n",
    "\t\tinput1 = input1.to(device)\n",
    "\t\tinput2 = input2.to(device)\n",
    "\t\tpert = nn.Parameter(torch.zeros_like(input2, requires_grad=True).to(device))\n",
    "\n",
    "\t\tfor z in range(input1.size(0)):\n",
    "\t\t\tif not rand_loc:\n",
    "\t\t\t\tstart_x = 224-patch_size-5\n",
    "\t\t\t\tstart_y = 224-patch_size-5\n",
    "\t\t\telse:\n",
    "\t\t\t\tstart_x = random.randint(0, 224-patch_size-1)\n",
    "\t\t\t\tstart_y = random.randint(0, 224-patch_size-1)\n",
    "\n",
    "\t\t\t# PASTE TRIGGER ON SOURCE IMAGES\n",
    "\t\t\tinput1[z, :, start_y:start_y+patch_size, start_x:start_x+patch_size] = trigger\n",
    "\n",
    "\t\t_, feat1 = model(input1)\n",
    "\t\tfeat1 = feat1.detach().clone()\n",
    "\n",
    "\t\tfor k in range(input1.size(0)):\n",
    "\t\t\timg_ctr = img_ctr+1\n",
    "\n",
    "\t\t\tfname = saveDir_patched + '/' + 'badnet_' + str(os.path.basename(path1[k])).split('.')[0] + '_' + 'epoch_' + str(epoch).zfill(2)\\\n",
    "\t\t\t\t\t+ str(img_ctr).zfill(5)+'.png'\n",
    "\n",
    "\t\t\tsave_image(input1[k].clone().cpu(), fname)\n",
    "\t\t\tnum_poisoned +=1\n",
    "\n",
    "\t\tfor j in range(num_iter):\n",
    "\t\t\tlr1 = adjust_learning_rate(lr, j)\n",
    "\n",
    "\t\t\t_, feat2 = model(input2+pert)\n",
    "\n",
    "\t\t\t# FIND CLOSEST PAIR WITHOUT REPLACEMENT\n",
    "\t\t\tfeat11 = feat1.clone()\n",
    "\t\t\tdist = torch.cdist(feat1, feat2)\n",
    "\t\t\tfor _ in range(feat2.size(0)):\n",
    "\t\t\t\tdist_min_index = (dist == torch.min(dist)).nonzero().squeeze()\n",
    "\t\t\t\tfeat1[dist_min_index[1]] = feat11[dist_min_index[0]]\n",
    "\t\t\t\tdist[dist_min_index[0], dist_min_index[1]] = 1e5\n",
    "\n",
    "\t\t\tloss1 = ((feat1-feat2)**2).sum(dim=1)\n",
    "\t\t\tloss = loss1.sum()\n",
    "\n",
    "\t\t\tlosses.update(loss.item(), input1.size(0))\n",
    "\n",
    "\t\t\tloss.backward()\n",
    "\n",
    "\t\t\tpert = pert- lr1*pert.grad\n",
    "\t\t\tpert = torch.clamp(pert, -eps1, eps1).detach_()\n",
    "\n",
    "\t\t\tpert = pert + input2\n",
    "\n",
    "\t\t\tpert = pert.clamp(0, 1)\n",
    "\n",
    "\t\t\tif j%100 == 0:\n",
    "\t\t\t\tlogging.info(\"Epoch: {:2d} | i: {} | iter: {:5d} | LR: {:2.4f} | Loss Val: {:5.3f} | Loss Avg: {:5.3f}\"\n",
    "\t\t\t\t\t\t\t .format(epoch, i, j, lr1, losses.val, losses.avg))\n",
    "\n",
    "\t\t\tif loss1.max().item() < 10 or j == (num_iter-1):\n",
    "\t\t\t\tfor k in range(input2.size(0)):\n",
    "\t\t\t\t\timg_ctr = img_ctr+1\n",
    "\t\t\t\t\tinput2_pert = (pert[k].clone().cpu())\n",
    "\n",
    "\t\t\t\t\tfname = saveDir_poison + '/' + 'loss_' + str(int(loss1[k].item())).zfill(5) + '_' + 'epoch_' + \\\n",
    "\t\t\t\t\t\t\tstr(epoch).zfill(2) + '_' + str(os.path.basename(path2[k])).split('.')[0] + '_' + \\\n",
    "\t\t\t\t\t\t\tstr(os.path.basename(path1[k])).split('.')[0] + '_kk_' + str(img_ctr).zfill(5)+'.png'\n",
    "\n",
    "\t\t\t\t\tsave_image(input2_pert, fname)\n",
    "\t\t\t\t\tnum_poisoned +=1\n",
    "\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\tpert = pert - input2\n",
    "\t\t\tpert.requires_grad = True\n",
    "\n",
    "\ttime_elapsed = time.time() - since\n",
    "\tlogging.info('Training complete one epoch in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.dirname(logfile)):\n",
    "        os.makedirs(os.path.dirname(logfile))\n",
    "\n",
    "logging.basicConfig(\n",
    "level=logging.INFO,\n",
    "format=\"%(asctime)s %(message)s\",\n",
    "handlers=[\n",
    "    logging.FileHandler(logfile, \"w\"),\n",
    "    logging.StreamHandler()\n",
    "])\n",
    "\n",
    "logging.info(\"Experiment ID: {}\".format(experimentID))\n",
    "\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    cudnn.deterministic = True\n",
    "    warnings.warn('You have chosen to seed training. '\n",
    "                    'This will turn on the CUDNN deterministic setting, '\n",
    "                    'which can slow down your training considerably! '\n",
    "                    'You may see unexpected behavior when restarting '\n",
    "                    'from checkpoints.')\n",
    "\n",
    "if device is not None:\n",
    "    logging.info(\"Use GPU: {} for training\".format(device))\n",
    "\n",
    "# create model\n",
    "logging.info(\"=> using pre-trained model '{}'\".format(\"alexnet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = NormalizeByChannelMeanStd(\n",
    "mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "model = alexnet(pretrained=True)\n",
    "model.eval()\n",
    "model = nn.Sequential(normalize, model)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # run one epoch\n",
    "    train(model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
